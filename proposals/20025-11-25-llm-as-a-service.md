---
layout: default
title: "ğŸ§  Sprogmodeller-as-a-service"
summary: "En skalerbar, LLM-as-a-Service lÃ¸sning bygget pÃ¥ Ã¥bne standarder, der muliggÃ¸rer solidarisk fair-use og energieffektiv drift."
author: "Jan Maack Kjerbye"
date: "2026-02-17"
tags: [AI, LLM, Kubernetes, Envoy, KServe, Kueue, Cloud Native]
status: "Udkast"
parent: "Proposals"
published: true
---

{% include header_metadata.html %}

Udkast  
{: .label .label-yellow }

## Baggrund

For at sikre en solidarisk adgang til sprogmodeller i OS2ai vil tilfÃ¸jelsen af en *â€œLLM as a Serviceâ€* lÃ¸sning til OS2ai kunne levere:
- **Flatrate betaling** (baseret pÃ¥ organisationsstÃ¸rrelse)
- **Fair-use solidaritetsmodel** (Fair-use pooling af ressourcer)
- **HÃ¸j sikkerhed** (Ingen lÃ¦k af data til eksterne API'er)

# Arkitektur anbefaling

> ### Det anbefales at fÃ¸lge internationale Cloud Native referencearktitekturer og implementere en lÃ¸sning baseret pÃ¥ **Envoy AI Gateway**, **Kueue** og **KServe**. En sÃ¥dan model adskiller adgangs- og ressource-styring fra selve model-afviklingen og sikrer en Ã¦gte cloud-native platform.

Denne lÃ¸sning:
- **Standardiserer adgang:** Bruger Envoy AI Gateway til at skabe Ã©n samlet, sikker indgang for alle organisationer.
- **Sikrer Fair-Use:** Bruger **Kueue** til at styre ressourcefordeling (GPU-kvoter) pÃ¥ tvÃ¦rs af organisationer gennem en solidarisk model.
- **LÃ¸skobler applikation og model:** Applikationer taler med en stabil gateway, mens modellerne kan opdateres eller skiftes i baggrunden uden nedetid.
- **FÃ¸lger 12/15-faktor principper:** Alt er deklarativt, stateless og konfigureret som kode (Config-as-Code) uden procedurale indgreb i containers.
- **Er 100% OSI-compliant:** Baseret udelukkende pÃ¥ CNCF open source-projekter, hvilket sikrer mod leverandÃ¸rbindinger.

## Komponenter
_Arkitekturlandskab_

---


```mermaid
flowchart TD
    subgraph "Applikations DomÃ¦ne"
        A[BrugergrÃ¦nseflade / Applikation]
    end

    subgraph "Infrastructure DomÃ¦ne"
        B[Envoy AI Gateway]-.-
        B1[Auth & Credentials]
    end

    subgraph "Inference DomÃ¦ne"
        C[Kueue Resource Manager]
        D[KServe InferenceServices]
        E[ModelMesh / vLLM]
    end

    A -->|mTLS / JWT| B
    B -->|Fair-Use Routing| C
    C --> D
    D --> E

    classDef Sky stroke-width:1px, stroke-dasharray:none, stroke:#374D7C, fill:#E2EBFF, color:#374D7C
    classDef Aqua stroke-width:1px, stroke-dasharray:none, stroke:#46EDC8, fill:#DEFFF8, color:#378E7A
    classDef Tech stroke-width:1px, stroke-dasharray:none, stroke:#378E7A, fill:#DEFFF8, color:#000
    
    A:::Sky
    B:::Aqua
    B1:::Tech
    C:::Aqua
    D:::Aqua
    E:::Aqua
```

### [Envoy AI Gateway](https://aigateway.envoyproxy.io/)
**Det strategiske kontrolpunkt.** HÃ¥ndterer identifikation af alle organisationer, injicerer API-nÃ¸gler sikkert (Credential Injection) og hÃ¥ndterer routing. Det sikrer, at applikationskoden aldrig "ser" fÃ¸lsomme nÃ¸gler, og at data ikke flyder til ikke-godkendte eksterne services.

### [Kueue](https://kueue.sigs.k8s.io/)
**Solidaritets-motoren.** Styrer hvem der fÃ¥r lov at bruge GPU'erne "lige nu". Hvis Ã©n myndighed bruger hele sin kvote, holder Kueue deres requests i kÃ¸, indtil der er ledig kapacitet, sÃ¥ de ikke "stjÃ¦ler" fra naboen, men stadig kan udnytte ledig overskudskapacitet via "borrowing".

### [KServe](https://kserve.github.io/website/) & [ModelMesh](https://kserve.github.io/archive/0.8/modelserving/mms/modelmesh/overview/)
**Produktionsmaskinen.** Automatiserer udrulning af modeller som skalerbare services. ModelMesh gÃ¸r det muligt at kÃ¸re mange forskellige modeller pÃ¥ fÃ¥ GPU'er ved at dele hukommelsen effektivt, hvilket er essentielt for at holde prisen nede i en flatrate-model.

# Forventede gevinster

### ğŸ’° Solidarisk og forudsigelig Ã¸konomi
Ved at bruge Envoy og Kueue kan vi garantere kapacitet til alle, samtidig med at vi tillader "lÃ¥n" af ledig kapacitet pÃ¥ tvÃ¦rs af platformen. Det fjerner behovet for kompleks token-afregning og understÃ¸tter en ren flatrate-struktur.

### ğŸ”’ Enterprise Sikkerhed & Governance
Al trafik monitoreres via standard OpenTelemetry logning. Vi fÃ¥r fuldt overblik over anvendelse pr. organisation pÃ¥ netvÃ¦rksniveau, hvilket gÃ¸r revision og auditering muligt uden specialudviklet kode.

### ğŸŒ± GrÃ¸n IT og optimeret drift
Scale-to-zero og intelligent GPU-pooling kan minimere tomgangskÃ¸rsel, hvilket reducerer bÃ¥de CO2-aftryk og de faktiske hostingomkostninger for de deltagende organisationer.

## Anvendte arkitekturprincipper  
Forslaget understÃ¸tter fÃ¸lgende fÃ¦llesoffentlige principper:

[â™»ï¸ Genbrug og fÃ¦lles lÃ¸sninger](https://arkitektur.digst.dk/principper-og-regler){: .btn .btn-green } [ğŸ‘ï¸ Ã…bne standarder](https://arkitektur.digst.dk/principper-og-regler){: .btn .btn-green } [ğŸ§© Modularitet og lÃ¸skobling](https://arkitektur.digst.dk/principper-og-regler){: .btn .btn-green } [ğŸ”’ Sikkerhed og robusthed](https://arkitektur.digst.dk/principper-og-regler){: .btn .btn-green } [ğŸŒ± GrÃ¸n IT](https://arkitektur.digst.dk/principper-og-regler){: .btn .btn-green } [ğŸ“ Governance](https://arkitektur.digst.dk/principper-og-regler){: .btn .btn-green }  

## Kilder
- [Envoy AI Gateway Reference Architecture](https://aigateway.envoyproxy.io/blog/envoy-ai-gateway-reference-architecture)
- [Kueue: Multi-tenant batch and AI scheduling](https://kueue.x-k8s.io/)
- [KServe: Scalable Model Serving](https://kserve.github.io/website/)
- [Cloud Native AI Whitepaper (CNCF)](https://www.cncf.io/reports/cloud-native-ai-whitepaper/)